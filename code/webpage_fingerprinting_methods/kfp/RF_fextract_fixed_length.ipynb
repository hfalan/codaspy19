{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing RF_fextract_fixed_length.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile RF_fextract_fixed_length.py\n",
    "# -1 is IN, 1 is OUT\n",
    "#file format: \"direction time size\"\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"Feeder functions\"\"\"\n",
    "\n",
    "def neighborhood(iterable):\n",
    "    iterator = iter(iterable)\n",
    "    prev = (0)\n",
    "    #item = iterator.next()  # throws StopIteration if empty.\n",
    "    item = iterator.__next__()  # throws StopIteration if empty.\n",
    "    for next in iterator:\n",
    "        yield (prev,item,next)\n",
    "        prev = item\n",
    "        item = next\n",
    "    yield (prev,item,None)\n",
    "\n",
    "def chunkIt(seq, num):\n",
    "  avg = len(seq) / float(num)\n",
    "  out = []\n",
    "  last = 0.0\n",
    "  while last < len(seq):\n",
    "    out.append(seq[int(last):int(last + avg)])\n",
    "    last += avg\n",
    "  return out\n",
    "\n",
    "\"\"\"Non-feeder functions\"\"\"\n",
    "\n",
    "def get_pkt_list2(trace_data):\n",
    "    first_line = trace_data[0]\n",
    "    first_line = first_line.split(\" \")\n",
    "\n",
    "    first_time = float(first_line[0])\n",
    "    dta = []\n",
    "    for line in trace_data:\n",
    "        a = line\n",
    "        b = a.split(\" \")\n",
    "\n",
    "        if float(b[1]) > 0:\n",
    "            #dta.append(((float(b[0])- first_time), abs(int(b[2])), 1))\n",
    "            dta.append(((float(b[0])- first_time), 1))\n",
    "        else:\n",
    "            #dta.append(((float(b[1]) - first_time), abs(int(b[2])), -1))\n",
    "            dta.append(((float(b[0]) - first_time), -1))\n",
    "    return dta\n",
    "\n",
    "def get_pkt_list(trace_data):\n",
    "    first_line = trace_data[0]\n",
    "    first_line = first_line.split(\" \")\n",
    "\n",
    "    first_time = float(first_line[0])\n",
    "    dta = []\n",
    "    for line in trace_data:\n",
    "        a = line\n",
    "        b = a.split(\" \")\n",
    "        dta.append(((float(b[0])- first_time), int(b[1])))\n",
    "\n",
    "    return dta\n",
    "\n",
    "\n",
    "def In_Out(list_data):\n",
    "    In = []\n",
    "    Out = []\n",
    "    for p in list_data:\n",
    "        if p[1] < 0:\n",
    "            In.append(p)\n",
    "        if p[1] > 0:\n",
    "            Out.append(p)\n",
    "    return In, Out\n",
    "\n",
    "############### TIME FEATURES #####################\n",
    "\n",
    "def inter_pkt_time(list_data):\n",
    "    times = [x[0] for x in list_data]\n",
    "    if len(times) < 2:\n",
    "        temp = [0,0]\n",
    "    else:\n",
    "        temp = []\n",
    "        for elem,next_elem in zip(times, times[1:]+[times[0]]):\n",
    "            temp.append(next_elem-elem)\n",
    "    return temp[:-1]\n",
    "\n",
    "def interarrival_times(list_data):\n",
    "    In, Out = In_Out(list_data)\n",
    "    IN = inter_pkt_time(In)\n",
    "    OUT = inter_pkt_time(Out)\n",
    "    TOTAL = inter_pkt_time(list_data)\n",
    "    return IN, OUT, TOTAL\n",
    "\n",
    "# def interarrival_maxminmeansd_stats(list_data):\n",
    "#     interstats = []\n",
    "#     In, Out, Total = interarrival_times(list_data)\n",
    "#     if In and Out:\n",
    "#         avg_in = sum(In)/float(len(In))\n",
    "#         avg_out = sum(Out)/float(len(Out))\n",
    "#         avg_total = sum(Total)/float(len(Total))\n",
    "#         interstats.append((max(In), max(Out), max(Total), avg_in, avg_out, avg_total, np.std(In), np.std(Out), np.std(Total), np.percentile(In, 75), np.percentile(Out, 75), np.percentile(Total, 75)))\n",
    "#     elif Out and not In:\n",
    "#         avg_out = sum(Out)/float(len(Out))\n",
    "#         avg_total = sum(Total)/float(len(Total))\n",
    "#         interstats.append((0, max(Out), max(Total), 0, avg_out, avg_total, 0, np.std(Out), np.std(Total), 0, np.percentile(Out, 75), np.percentile(Total, 75)))\n",
    "#     elif In and not Out:\n",
    "#         avg_in = sum(In)/float(len(In))\n",
    "#         avg_total = sum(Total)/float(len(Total))\n",
    "#         interstats.append((max(In), 0, max(Total), avg_in, 0, avg_total, np.std(In), 0, np.std(Total), np.percentile(In, 75), 0, np.percentile(Total, 75)))\n",
    "#     else:\n",
    "#         interstats.append(([0]*15))\n",
    "#     return interstats\n",
    "\n",
    "def interarrival_maxminmeansd_stats(list_data):\n",
    "    interstats = []\n",
    "    In, Out, Total = interarrival_times(list_data)\n",
    "    \n",
    "    if In and Out:\n",
    "        avg_in = sum(In)/float(len(In))\n",
    "        avg_out = sum(Out)/float(len(Out))\n",
    "        avg_total = sum(Total)/float(len(Total))\n",
    "        interstats.append((max(In), max(Out), max(Total), avg_in, avg_out, avg_total, np.std(In), np.std(Out), np.std(Total), np.percentile(In, 75), np.percentile(Out, 75), np.percentile(Total, 75)))\n",
    "    elif Out and not In:\n",
    "        avg_out = sum(Out)/float(len(Out))\n",
    "        avg_total = sum(Total)/float(len(Total))\n",
    "        interstats.append((0, max(Out), max(Total), 0, avg_out, avg_total, 0, np.std(Out), np.std(Total), 0, np.percentile(Out, 75), np.percentile(Total, 75)))\n",
    "    elif In and not Out:\n",
    "        avg_in = sum(In)/float(len(In))\n",
    "        avg_total = sum(Total)/float(len(Total))\n",
    "        interstats.append((max(In), 0, max(Total), avg_in, 0, avg_total, np.std(In), 0, np.std(Total), np.percentile(In, 75), 0, np.percentile(Total, 75)))\n",
    "    else:\n",
    "        interstats.append(([0]*12))\n",
    "\n",
    "    assert len(interstats[0]) == 12\n",
    "    return interstats\n",
    "\n",
    "def time_percentile_stats(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    In, Out = In_Out(Total)\n",
    "    In1 = [x[0] for x in In]\n",
    "    Out1 = [x[0] for x in Out]\n",
    "    Total1 = [x[0] for x in Total]\n",
    "    STATS = []\n",
    "    if In1:\n",
    "        STATS.append(np.percentile(In1, 25)) # return 25th percentile\n",
    "        STATS.append(np.percentile(In1, 50))\n",
    "        STATS.append(np.percentile(In1, 75))\n",
    "        STATS.append(np.percentile(In1, 100))\n",
    "    if not In1:\n",
    "        STATS.extend(([0]*4))\n",
    "    if Out1:\n",
    "        STATS.append(np.percentile(Out1, 25)) # return 25th percentile\n",
    "        STATS.append(np.percentile(Out1, 50))\n",
    "        STATS.append(np.percentile(Out1, 75))\n",
    "        STATS.append(np.percentile(Out1, 100))\n",
    "    if not Out1:\n",
    "        STATS.extend(([0]*4))\n",
    "    if Total1:\n",
    "        STATS.append(np.percentile(Total1, 25)) # return 25th percentile\n",
    "        STATS.append(np.percentile(Total1, 50))\n",
    "        STATS.append(np.percentile(Total1, 75))\n",
    "        STATS.append(np.percentile(Total1, 100))\n",
    "    if not Total1:\n",
    "        STATS.extend(([0]*4))\n",
    "    return STATS\n",
    "\n",
    "def number_pkt_stats(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    In, Out = In_Out(Total)\n",
    "    return len(In), len(Out), len(Total)\n",
    "\n",
    "def first_and_last_30_pkts_stats(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    first30 = Total[:30]\n",
    "    last30 = Total[-30:]\n",
    "    first30in = []\n",
    "    first30out = []\n",
    "    for p in first30:\n",
    "        if p[1] < 0:\n",
    "            first30in.append(p)\n",
    "        if p[1] > 0:\n",
    "            first30out.append(p)\n",
    "    last30in = []\n",
    "    last30out = []\n",
    "    for p in last30:\n",
    "        if p[1] < 0:\n",
    "            last30in.append(p)\n",
    "        if p[1] > 0:\n",
    "            last30out.append(p)\n",
    "    stats= []\n",
    "    stats.append(len(first30in))\n",
    "    stats.append(len(first30out))\n",
    "    stats.append(len(last30in))\n",
    "    stats.append(len(last30out))\n",
    "    return stats\n",
    "\n",
    "#concentration of outgoing packets in chunks of 20 packets\n",
    "def pkt_concentration_stats(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    chunks= [Total[x:x+20] for x in range(0, len(Total), 20)]\n",
    "    concentrations = []\n",
    "    for item in chunks:\n",
    "        c = 0\n",
    "        for p in item:\n",
    "            if p[1] > 0:\n",
    "                c+=1\n",
    "        concentrations.append(c)\n",
    "    return np.std(concentrations), sum(concentrations)/float(len(concentrations)), np.percentile(concentrations, 50), min(concentrations), max(concentrations), concentrations\n",
    "\n",
    "#Average number packets sent and received per second\n",
    "def number_per_sec(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    last_time = Total[-1][0]\n",
    "    last_second = math.ceil(last_time)\n",
    "    temp = []\n",
    "    l = []\n",
    "    for i in range(1, int(last_second)+1):\n",
    "        c = 0\n",
    "        for p in Total:\n",
    "            if p[0] <= i:\n",
    "                c+=1\n",
    "        temp.append(c)\n",
    "    for prev,item,next in neighborhood(temp):\n",
    "        x = item - prev\n",
    "        l.append(x)\n",
    "    avg_number_per_sec = sum(l)/float(len(l))\n",
    "    return avg_number_per_sec, np.std(l), np.percentile(l, 50), min(l), max(l), l\n",
    "\n",
    "#Variant of packet ordering features from http://cacr.uwaterloo.ca/techreports/2014/cacr2014-05.pdf\n",
    "def avg_pkt_ordering_stats(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    for p in Total:\n",
    "        if p[1] > 0:\n",
    "            temp1.append(c1)\n",
    "        c1+=1\n",
    "        if p[1] < 0:\n",
    "            temp2.append(c2)\n",
    "        c2+=1\n",
    "    avg_in = sum(temp1)/float(len(temp1))\n",
    "    avg_out = sum(temp2)/float(len(temp2))\n",
    "\n",
    "    return avg_in, avg_out, np.std(temp1), np.std(temp2)\n",
    "\n",
    "def perc_inc_out(trace_data):\n",
    "    Total = get_pkt_list(trace_data)\n",
    "    In, Out = In_Out(Total)\n",
    "    percentage_in = len(In)/float(len(Total))\n",
    "    percentage_out = len(Out)/float(len(Total))\n",
    "    return percentage_in, percentage_out\n",
    "\n",
    "############### SIZE FEATURES #####################\n",
    "\n",
    "def total_size(list_data):\n",
    "   return sum([int(x[1]) for x in list_data])\n",
    "\n",
    "def in_out_size(list_data):\n",
    "   In, Out = In_Out(list_data)\n",
    "   size_in = sum([x[1] for x in In])\n",
    "   size_out = sum([x[1] for x in Out])\n",
    "   return size_in, size_out\n",
    "\n",
    "def average_total_pkt_size(list_data):\n",
    "   return np.mean([x[1] for x in list_data])\n",
    "\n",
    "def average_in_out_pkt_size(list_data):\n",
    "   In, Out = In_Out(list_data)\n",
    "   average_size_in = np.mean([x[1] for x in In])\n",
    "   average_size_out = np.mean([x[1] for x in Out])\n",
    "   return average_size_in, average_size_out\n",
    "\n",
    "def variance_total_pkt_size(list_data):\n",
    "   return np.var([x[1] for x in list_data])\n",
    "\n",
    "def variance_in_out_pkt_size(list_data):\n",
    "   In, Out = In_Out(list_data)\n",
    "   var_size_in = np.var([x[1] for x in In])\n",
    "   var_size_out = np.var([x[1] for x in Out])\n",
    "   return var_size_in, var_size_out\n",
    "\n",
    "def std_total_pkt_size(list_data):\n",
    "   return np.std([x[1] for x in list_data])\n",
    "\n",
    "def std_in_out_pkt_size(list_data):\n",
    "   In, Out = In_Out(list_data)\n",
    "   std_size_in = np.std([x[1] for x in In])\n",
    "   std_size_out = np.std([x[1] for x in Out])\n",
    "   return std_size_in, std_size_out\n",
    "\n",
    "def max_in_out_pkt_size(list_data):\n",
    "   In, Out = In_Out(list_data)\n",
    "   max_size_in = max([x[1] for x in In])\n",
    "   max_size_out = max([x[1] for x in Out])\n",
    "   return max_size_in, max_size_out\n",
    "\n",
    "def unique_pkt_lengths(list_data):\n",
    "   pass\n",
    "\n",
    "############### FEATURE FUNCTION #####################\n",
    "\n",
    "\n",
    "#If size information available add them in to function below\n",
    "def TOTAL_FEATURES(trace_data, max_size=175):\n",
    "    list_data = get_pkt_list(trace_data)\n",
    "    ALL_FEATURES = []\n",
    "\n",
    "    # ------TIME--------\n",
    "    intertimestats = [x for x in interarrival_maxminmeansd_stats(list_data)[0]]\n",
    "    timestats = time_percentile_stats(trace_data)\n",
    "    number_pkts = list(number_pkt_stats(trace_data))\n",
    "    thirtypkts = first_and_last_30_pkts_stats(trace_data)\n",
    "    stdconc, avgconc, medconc, minconc, maxconc, conc = pkt_concentration_stats(trace_data)\n",
    "    avg_per_sec, std_per_sec, med_per_sec, min_per_sec, max_per_sec, per_sec = number_per_sec(trace_data)\n",
    "    avg_order_in, avg_order_out, std_order_in, std_order_out = avg_pkt_ordering_stats(trace_data)\n",
    "    perc_in, perc_out = perc_inc_out(trace_data)\n",
    "\n",
    "    altconc = []\n",
    "    alt_per_sec = []\n",
    "    altconc = [sum(x) for x in chunkIt(conc, 70)]\n",
    "    alt_per_sec = [sum(x) for x in chunkIt(per_sec, 20)]\n",
    "    if len(altconc) == 70:\n",
    "        altconc.append(0)\n",
    "    if len(alt_per_sec) == 20:\n",
    "        alt_per_sec.append(0)\n",
    "\n",
    "    # ------SIZE--------\n",
    "\n",
    "    tot_size = total_size(list_data)\n",
    "    in_size, out_size = in_out_size(list_data)\n",
    "    avg_total_size = average_total_pkt_size(list_data)\n",
    "    avg_size_in, avg_size_out = average_in_out_pkt_size(list_data)\n",
    "    var_total_size = variance_total_pkt_size(list_data)\n",
    "    var_size_in, var_size_out = variance_in_out_pkt_size(list_data)\n",
    "    std_total_size = std_total_pkt_size(list_data)\n",
    "    std_size_in, std_size_out = std_in_out_pkt_size(list_data)\n",
    "    max_size_in, max_size_out = max_in_out_pkt_size(list_data)\n",
    "\n",
    "    # TIME Features\n",
    "    ALL_FEATURES.extend(intertimestats)\n",
    "    ALL_FEATURES.extend(timestats)\n",
    "    ALL_FEATURES.extend(number_pkts)\n",
    "    ALL_FEATURES.extend(thirtypkts)\n",
    "    ALL_FEATURES.append(stdconc)\n",
    "    ALL_FEATURES.append(avgconc)\n",
    "    ALL_FEATURES.append(avg_per_sec)\n",
    "    ALL_FEATURES.append(std_per_sec)\n",
    "    ALL_FEATURES.append(avg_order_in)\n",
    "    ALL_FEATURES.append(avg_order_out)\n",
    "    ALL_FEATURES.append(std_order_in)\n",
    "    ALL_FEATURES.append(std_order_out)\n",
    "    ALL_FEATURES.append(medconc)\n",
    "    ALL_FEATURES.append(med_per_sec)\n",
    "    ALL_FEATURES.append(min_per_sec)\n",
    "    ALL_FEATURES.append(max_per_sec)\n",
    "    ALL_FEATURES.append(maxconc)\n",
    "    ALL_FEATURES.append(perc_in)\n",
    "    ALL_FEATURES.append(perc_out)\n",
    "    ALL_FEATURES.extend(altconc)\n",
    "    ALL_FEATURES.extend(alt_per_sec)\n",
    "    ALL_FEATURES.append(sum(altconc))\n",
    "    ALL_FEATURES.append(sum(alt_per_sec))\n",
    "    ALL_FEATURES.append(sum(intertimestats))\n",
    "    ALL_FEATURES.append(sum(timestats))\n",
    "    ALL_FEATURES.append(sum(number_pkts))\n",
    "\n",
    "    #SIZE FEATURES\n",
    "    ALL_FEATURES.append(tot_size)\n",
    "    ALL_FEATURES.append(in_size)\n",
    "    ALL_FEATURES.append(out_size)\n",
    "    ALL_FEATURES.append(avg_total_size)\n",
    "    ALL_FEATURES.append(avg_size_in)\n",
    "    ALL_FEATURES.append(avg_size_out)\n",
    "    ALL_FEATURES.append(var_total_size)\n",
    "    ALL_FEATURES.append(var_size_in)\n",
    "    ALL_FEATURES.append(var_size_out)\n",
    "    ALL_FEATURES.append(std_total_size)\n",
    "    ALL_FEATURES.append(std_size_in)\n",
    "    ALL_FEATURES.append(std_size_out)\n",
    "    ALL_FEATURES.append(max_size_in)\n",
    "    ALL_FEATURES.append(max_size_out)\n",
    "    \n",
    "    assert len(ALL_FEATURES) == 157\n",
    "\n",
    "    # This is optional, since all other features are of equal size this gives the first n features\n",
    "    # of this particular feature subset, some may be padded with 0's if too short.\n",
    "\n",
    "    ALL_FEATURES.extend(conc)\n",
    "\n",
    "    ALL_FEATURES.extend(per_sec)\n",
    "\n",
    "\n",
    "    while len(ALL_FEATURES)<max_size:\n",
    "        ALL_FEATURES.append(0)\n",
    "    features = ALL_FEATURES[:max_size]\n",
    "    return tuple(features)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
