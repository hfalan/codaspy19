{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting attack.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile attack.py\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from commands import *\n",
    "from gaussian_tools import generate_gaussians, get_gaussian_features\n",
    "import scipy.sparse\n",
    "\n",
    "class Domain(object):\n",
    "\n",
    "    def __init__(self, domain_dir, domain_name, training_dir, testing_dir, holdout_dir):\n",
    "        self.domain_name = domain_name\n",
    "        self.domain_root = os.path.join(domain_dir, domain_name)\n",
    "        if not os.path.exists(self.domain_root):\n",
    "            os.makedirs(self.domain_root)\n",
    "        self.training_points = os.path.join(training_dir, domain_name)\n",
    "        self.testing_points = os.path.join(testing_dir, domain_name)\n",
    "        self.holdout_points = os.path.join(holdout_dir, domain_name)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.domain_name\n",
    "\n",
    "    def _get_centroids(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'centroids')\n",
    "\n",
    "    def _get_assignments(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'assignments')\n",
    "\n",
    "    def _get_gaussians(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'gaussians')\n",
    "\n",
    "    def _get_training_file(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'training_features')\n",
    "\n",
    "    def _get_testing_file(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'testing_features')\n",
    "\n",
    "    def _get_model_file(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'model')\n",
    "\n",
    "    def _get_prediction_file(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'prediction')\n",
    "\n",
    "    def _get_accuracy_file(self, job):\n",
    "        return os.path.join(self.domain_root, job, 'lr_accuracy')\n",
    "\n",
    "    def load_training_data(self):\n",
    "        handle = open(self.training_points)\n",
    "        self.num_training_points = len(handle.read().strip().split('\\n'))\n",
    "        handle.close()\n",
    "\n",
    "    def get_kmeans_jobs(self):\n",
    "        kmeans_jobs = []\n",
    "        k_range = list(filter(lambda x: x < self.num_training_points / 3, [4000, 1000, 500]))\n",
    "        if len(k_range) < 3:\n",
    "            k_range = [max(1, self.num_training_points / 3)] + k_range\n",
    "        for k in k_range:\n",
    "            for init in ['random']:\n",
    "                for batch_size in [100]:\n",
    "                    for iterations in [500]:\n",
    "                        dir_name = 'k_%s__in_%s__b_%s__it_%s' % (k, init, batch_size, iterations)\n",
    "                        kmeans_dir = os.path.join(self.domain_root, dir_name)\n",
    "                        if not os.path.exists(kmeans_dir):\n",
    "                            os.makedirs(kmeans_dir)\n",
    "                        kmeans_jobs.append((self._get_centroids(dir_name), self.training_points,\n",
    "                                            k, init, batch_size, iterations))\n",
    "        return kmeans_jobs\n",
    "\n",
    "    def get_assignment_jobs(self):\n",
    "        jobs = os.listdir(self.domain_root)\n",
    "        jobs = [j for j in jobs if re.match('k_.*', j)]\n",
    "        assignment_jobs = []\n",
    "        for j in jobs:\n",
    "            assignment_jobs.append((self.training_points, self._get_centroids(j), self._get_assignments(j)))\n",
    "        return assignment_jobs\n",
    "                                   \n",
    "    def get_gaussian_jobs(self):\n",
    "        jobs = os.listdir(self.domain_root)\n",
    "        jobs = [j for j in jobs if re.match('k_.*', j)]\n",
    "        gaussian_jobs = []\n",
    "        for j in jobs:\n",
    "            gaussian_jobs.append((self.training_points, self._get_assignments(j), self._get_gaussians(j)))\n",
    "        return gaussian_jobs\n",
    "\n",
    "    def _load_gaussians(self, gaussian_file):\n",
    "        gaussians = []\n",
    "        handle = open(gaussian_file)\n",
    "        for line in handle:\n",
    "            mean_0, mean_1, covar_0, covar_1, covar_2, covar_3 = [float(t) for t in line.split()]\n",
    "            mean = np.array([mean_0, mean_1])\n",
    "            covar = np.array([covar_0, covar_1, covar_2, covar_3]).reshape(2,2)\n",
    "            coef = ((2.0 * np.pi) ** -1.0) * (np.linalg.det(covar) ** -.5)\n",
    "            covarinv = np.linalg.inv(covar)\n",
    "            gaussians.append((coef, mean, covarinv))\n",
    "        handle.close()\n",
    "        return gaussians\n",
    "        \n",
    "    def get_cluster_sets(self):\n",
    "#         print('Getting Cluster Sets: %s' % self.domain_name)\n",
    "        jobs = os.listdir(self.domain_root)\n",
    "        jobs = [j for j in jobs if re.match('k_.*', j)]\n",
    "        feature_jobs = []\n",
    "        for j in jobs:\n",
    "            gaussians = self._load_gaussians(self._get_gaussians(j))\n",
    "            feature_jobs.append((gaussians, self._get_training_file(j), self._get_testing_file(j)))\n",
    "        return feature_jobs\n",
    "\n",
    "    def _load_points(self, point_file):\n",
    "        point_dict = {}  # sample :-> [points]\n",
    "        label_dict = {}  # sample :-> label\n",
    "        if not os.path.exists(point_file):\n",
    "            return (point_dict, label_dict.items())\n",
    "        handle = open(point_file)\n",
    "        for line in handle:\n",
    "#             label, x, y, sample_name = re.match('([0-9-]+) 1:(\\d+) 2:(\\d+) # ([a-z0-9_.-]+)', line).groups()\n",
    "            label, x, y, sample_name = re.match('([0-9-]+) 1:(\\d+) 2:(\\d+) # (.+)', line).groups()\n",
    "            if sample_name not in point_dict:\n",
    "                point_dict[sample_name] = []\n",
    "            point_dict[sample_name].append(np.array([int(x), int(y)]))\n",
    "            label_dict[sample_name] = label\n",
    "        handle.close()\n",
    "        return (point_dict, label_dict.items())\n",
    "            \n",
    "    def get_points(self, sample_orders = None):\n",
    "#         print('Getting Points: %s' % self.domain_name)\n",
    "        # load points\n",
    "        if not sample_orders:\n",
    "            train_points, train_sample_labels = self._load_points(self.training_points)\n",
    "            test_points, test_sample_labels = self._load_points(self.testing_points)\n",
    "        else:\n",
    "            train_points, _ = self._load_points(self.training_points)\n",
    "            tmp_points, _ = self._load_points(self.testing_points)\n",
    "            train_points.update(tmp_points)\n",
    "            test_points, _ = self._load_points(self.holdout_points)\n",
    "            train_sample_labels, test_sample_labels = sample_orders\n",
    "        # populate points and range_data\n",
    "        points = []\n",
    "        range_data = []\n",
    "        for (idx, (sample, _)) in enumerate(train_sample_labels):\n",
    "            if sample in train_points:\n",
    "                sample_points = train_points[sample]\n",
    "                range_data.append((idx, len(points), len(points) + len(sample_points)))\n",
    "                points.extend(sample_points)\n",
    "        cutoff = len(train_sample_labels)\n",
    "        for (idx, (sample, _)) in enumerate(test_sample_labels):\n",
    "            if sample in test_points:\n",
    "                sample_points = test_points[sample]\n",
    "                range_data.append((idx + cutoff, len(points), len(points) + len(sample_points)))\n",
    "                points.extend(sample_points)\n",
    "        # return final values\n",
    "        return (points, range_data, list(train_sample_labels), list(test_sample_labels))\n",
    "\n",
    "    def get_train_jobs(self):\n",
    "        jobs = os.listdir(self.domain_root)\n",
    "        jobs = [j for j in jobs if re.match('k_.*', j)]\n",
    "        train_jobs = []\n",
    "        for j in jobs:\n",
    "            train_jobs.append((self._get_training_file(j), self._get_model_file(j)))\n",
    "        return train_jobs\n",
    "\n",
    "    def get_predict_jobs(self):\n",
    "        jobs = os.listdir(self.domain_root)\n",
    "        jobs = [j for j in jobs if re.match('k_.*', j)]\n",
    "        predict_jobs = []\n",
    "        for j in jobs:\n",
    "            predict_jobs.append((self._get_testing_file(j), self._get_model_file(j),\n",
    "                                 self._get_prediction_file(j), self._get_accuracy_file(j)))\n",
    "        return predict_jobs\n",
    "\n",
    "    def get_best_gaussians(self):\n",
    "        jobs = os.listdir(self.domain_root)\n",
    "        jobs = [j for j in jobs if re.match('k_.*', j)]\n",
    "        best_accuracy = None\n",
    "        for j in jobs:\n",
    "            handle = open(self._get_accuracy_file(j))\n",
    "            accuracy = float(handle.read().strip().split('\\n')[0].split(':')[1])\n",
    "            handle.close()\n",
    "            if best_accuracy == None or accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_gaussians = self._load_gaussians(self._get_gaussians(j))\n",
    "        return best_gaussians\n",
    "    \n",
    "    \n",
    "def write_features(train_file, test_file, train_sample_labels, test_sample_labels, all_features, sparse):\n",
    "    def helper(path, features, sample_labels, sparse):\n",
    "        handle = open(path, 'w')\n",
    "        assert features.shape[0] == len(sample_labels)\n",
    "        for i in range(len(sample_labels)):\n",
    "            sample_features = features[i, :]\n",
    "            if sparse:\n",
    "                sample_features = sample_features.toarray()[0]\n",
    "            sample_name, sample_label = sample_labels[i]\n",
    "            handle.write('%s ' % sample_label)\n",
    "            for idx, value in enumerate(sample_features):\n",
    "                if value > .0000000001:\n",
    "                    handle.write('%d:%.10f ' % (idx + 1, value))\n",
    "            handle.write('# %s\\n' % sample_name)\n",
    "        handle.close()\n",
    "    num_samples = len(train_sample_labels) + len(test_sample_labels)\n",
    "    assert all_features.shape[0] == num_samples\n",
    "    training_features = all_features[np.arange(len(train_sample_labels)), :]\n",
    "    testing_features = all_features[np.arange(len(train_sample_labels), num_samples), :]\n",
    "    helper(train_file, training_features, train_sample_labels, sparse)\n",
    "    helper(test_file, testing_features, test_sample_labels, sparse)\n",
    "    \n",
    "    \n",
    "def main(domains, train_list, test_list, hold_list, packet_size_features, output_dir, n_cpu):\n",
    "    \n",
    "    pool = Pool(n_cpu)\n",
    "    \n",
    "#     extract centroids\n",
    "    kmeans_jobs = itertools.chain(*[d.get_kmeans_jobs() for d in domains])\n",
    "    pool.starmap(extract_centroids, kmeans_jobs)\n",
    "    # generate assignments\n",
    "    assignment_jobs = itertools.chain(*[d.get_assignment_jobs() for d in domains])\n",
    "    pool.starmap(generate_assignments, assignment_jobs)\n",
    "    # generate gaussians\n",
    "    gaussian_jobs = itertools.chain(*[d.get_gaussian_jobs() for d in domains])\n",
    "    pool.starmap(generate_gaussians, gaussian_jobs)\n",
    "    \n",
    "    # generate features\n",
    "    all_points = [d.get_points() for d in domains]\n",
    "    all_cluster_sets = [d.get_cluster_sets() for d in domains]\n",
    "    for (points, clusters, domain) in zip(all_points, all_cluster_sets, domains):\n",
    "#         print('Processing: %s' % domain)\n",
    "        point_matrix, range_data, train_sample_labels, test_sample_labels = points\n",
    "        num_samples = len(train_sample_labels) + len(test_sample_labels)\n",
    "        for (gaussians, train_file, test_file) in clusters:\n",
    "            all_features = get_gaussian_features(num_samples, pool, [(point_matrix, range_data, gaussians)])\n",
    "            write_features(train_file, test_file, train_sample_labels, test_sample_labels, all_features, False)\n",
    "            \n",
    "    # train models\n",
    "    train_jobs = itertools.chain(*[d.get_train_jobs() for d in domains])\n",
    "    pool.starmap(train_model, train_jobs)\n",
    "    \n",
    "    # run predict\n",
    "    predict_jobs = itertools.chain(*[d.get_predict_jobs() for d in domains])\n",
    "    pool.starmap(predict, predict_jobs)\n",
    "    \n",
    "    \n",
    "    # generate features using best sets of gaussians\n",
    "    sample_orders = (train_list + test_list, hold_list)\n",
    "    all_points = [d.get_points(sample_orders = sample_orders) for d in domains]\n",
    "    best_gaussians = [d.get_best_gaussians() for d in domains]\n",
    "    jobs = []\n",
    "    for (points, gaussians, domain) in zip(all_points, best_gaussians, domains):\n",
    "        point_matrix, range_data, _, _ = list(points)        \n",
    "        jobs.append((point_matrix, range_data, gaussians))\n",
    "        \n",
    "    burst_pair_features = get_gaussian_features(len(train_list) + len(test_list) + len(hold_list), pool, jobs)\n",
    "    burst_pair_features = scipy.sparse.csr_matrix(burst_pair_features)\n",
    "    \n",
    "    all_features = scipy.sparse.hstack([packet_size_features, burst_pair_features], format = 'csr')\n",
    "#     all_features = packet_size_features\n",
    "#     all_features = burst_pair_features\n",
    "    TRAINING_FEATURES = os.path.join(output_dir, 'training_features')\n",
    "    HOLDOUT_FEATURES = os.path.join(output_dir, 'holdout_features')\n",
    "    write_features(TRAINING_FEATURES, HOLDOUT_FEATURES, train_list + test_list, hold_list, all_features, True)\n",
    "    # train composite model\n",
    "    MODEL = os.path.join(output_dir, 'model')\n",
    "    train_model(TRAINING_FEATURES, MODEL, args = '-s 7 -c 128')\n",
    "    # do final prediction\n",
    "    PREDICT = os.path.join(output_dir, 'predict')\n",
    "    predict(HOLDOUT_FEATURES, MODEL, PREDICT, os.path.join(output_dir, 'lr_accuracy'), args = '-b 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
